### ![图片](https://uploader.shimo.im/f/X3cZM6by0A4jbbFI.png!thumbnail)

### Kafka的使用场景：

#### 活动跟踪：

Kafka 可以用来跟踪用户行为，比如我们经常回去淘宝购物，你打开淘宝的那一刻，你的登陆信息，登陆次数都会作为消息传输到 Kafka，做一些好物推荐。

#### 流式处理：

流式处理是有一个能够提供多种应用程序的领域。

#### 日志记录：

把数据库的更新发送到 Kafka 上，用来记录数据库的更新时间，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。

### Kafka的特性：

#### **高吞吐、低延迟：**

kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒。

#### **高伸缩性：**

 每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中。

#### **持久性****、可****靠性：**

 Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，Zookeeper 我们知道它的数据能够持久存储。

#### **容错性：** 

允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作。

#### **高并发： **

支持数千个客户端同时读写。

### Kafka的作用：

1. 解耦
2. 异步
3. 削峰
### Kafka如何保证消息的顺序性？

可以通过分区策略体现消息顺序性。分区策略有轮询策略、随机策略、按消息键保序策略。

### Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？

* **序列化器：**生产者需要用序列化器（Serializer）把对象转换成字节数组才能通过网络发送给 Kafka。而在对侧，消费者需要用反序列化器（Deserializer）把从 Kafka 中收到的字节数组转换成相应的对象。
* **分区器：**分区器的作用就是为消息分配分区。如果消息 ProducerRecord 中没有指定 partition 字段，那么就需要依赖分区器，根据 key 这个字段来计算 partition 的值。
* Kafka 一共有两种拦截器：**生产者拦截器**和**消费者拦截器**。
  * 生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。
  * 消费者拦截器主要在消费到消息或在提交消费位移时进行一些定制化的操作。

消息在通过 send() 方法发往 broker 的过程中，有可能需要经过拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）的一系列作用之后才能被真正地发往 broker。拦截器（下一章会详细介绍）一般不是必需的，而序列化器是必需的。消息经过序列化之后就需要确定它发往的分区，如果消息 ProducerRecord 中指定了 partition 字段，那么就不需要分区器的作用，因为 partition 代表的就是所要发往的分区号。

处理顺序 ：拦截器->序列化器->分区器

KafkaProducer 在将消息序列化和计算分区之前会调用生产者拦截器的 onSend() 方法来对消息进行相应的定制化操作。

然后生产者需要用序列化器（Serializer）把对象转换成字节数组才能通过网络发送给 Kafka。

最后可能会被发往分区器为消息分配分区。

### Kafka生产者客户端中使用了几个线程来处理？分别是什么？

整个生产者客户端由两个线程协调运行，这两个线程分别为**主线程**和 **Sender 线程**（发送线程）。在主线程中由 KafkaProducer 创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器（RecordAccumulator，也称为消息收集器）中。Sender 线程负责从 RecordAccumulator 中获取消息并将其发送到 Kafka 中。

### 有哪些情形会造成重复消费？

**Rebalance（重平衡）**

一个consumer正在消费一个分区的一条消息，还没有消费完，发生了rebalance(加入了一个consumer)，从而导致这条消息没有消费成功，rebalance后，另一个consumer又把这条消息消费一遍。

### 消费者重平衡（高可用性、伸缩性）

消费者通过向组织协调者（Kafka Broker）发送心跳来维护自己是消费者组的一员并确认其拥有的分区。对于不同不的消费群体来说，其组织协调者可以是不同的。只要消费者定期发送心跳，就会认为消费者是存活的并处理其分区中的消息。当消费者检索记录或者提交它所消费的记录时就会发送心跳。

如果过了一段时间 Kafka 停止发送心跳了，会话（Session）就会过期，组织协调者就会认为这个 Consumer 已经死亡，就会触发一次重平衡。如果消费者宕机并且停止发送消息，组织协调者会等待几秒钟，确认它死亡了才会触发重平衡。在这段时间里，**死亡的消费者将不处理任何消息**。在清理消费者时，消费者将通知协调者它要离开群组，组织协调者会触发一次重平衡，尽量降低处理停顿。

也就是说，在重平衡期间，消费者组中的消费者实例都会停止消费，等待重平衡的完成。而且重平衡这个过程很慢......

###  那些情景下会造成消息漏消费？

**acks没有设置为all**

如果在broker还没把消息同步到其他broker的时候宕机了，那么消息将会丢失。

### KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？

线程封闭，即为每个线程实例化一个 KafkaConsumer 对象

![图片](https://uploader.shimo.im/f/KMkbhEwIOF918Rj4.png!thumbnail)

一个线程对应一个 KafkaConsumer 实例，我们可以称之为消费线程。一个消费线程可以消费一个或多个分区中的消息，所有的消费线程都隶属于同一个消费组。

### topic的分区数可不可以增加？

当分区数增加时，就会触发订阅该主题的所有 Group 开启 Rebalance。 在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成。

### 消费者与生产者的工作流程：

**写数据的时候，**生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）

**消费的时候，**只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

### 如何保证消息不被重复消费（幂等性）

比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。



 

